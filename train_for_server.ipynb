{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/gibiee/Measure_BoneAge/blob/master/%EB%BC%88%20%EB%82%98%EC%9D%B4%20%EC%B8%A1%EC%A0%95(Male%20%EC%A0%84%EC%9A%A9).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MUI2rI_KoEU9"},"outputs":[],"source":["import tensorflow as tf\n","\n","male_model = tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224,224,1), classes=1, classifier_activation=None)\n","female_model = tf.keras.applications.InceptionV3(weights=None, include_top=True, input_shape=(224,224,1), classes=1, classifier_activation=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w7t7mzeEoEa1"},"outputs":[],"source":["male_model.compile(loss='mae', optimizer='adam')\n","female_model.compile(loss='mae', optimizer='adam')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AcAOJ3PveDq"},"outputs":[],"source":["import pandas as pd\n","\n","csv_train=pd.read_csv('./boneage-training-dataset.csv')\n","\n","for i in range(len(csv_train['id'])):\n","  csv_train.loc[i,\"id\"] = f\"{csv_train['id'][i]}.png\"\n","\n","printf(\"\\n******************** boneage-training-dataset ****************************\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YUlQ0U_pZuA7"},"outputs":[],"source":["male_df = csv_train.loc[csv_train.male == True]\n","female_df = csv_train.loc[csv_train.male == False]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-2nW0QyN5Qnx"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2) # random으로 validation 뽑음\n","\n","train_generator_m = datagen.flow_from_dataframe(male_df, directory='./boneage-training-dataset', x_col='id', y_col='boneage',\n","                                              target_size=(224,224), color_mode='grayscale',\n","                                              class_mode='raw', subset='training')\n","valid_generator_m = datagen.flow_from_dataframe(male_df, directory='./boneage-training-dataset', x_col='id', y_col='boneage',\n","                                              target_size=(224,224), color_mode='grayscale', \n","                                              class_mode='raw', subset='validation', shuffle=False)\n","\n","\n","train_generator_f = datagen.flow_from_dataframe(female_df, directory='./boneage-training-dataset', x_col='id', y_col='boneage',\n","                                              target_size=(224,224), color_mode='grayscale',\n","                                              class_mode='raw', subset='training')\n","valid_generator_f = datagen.flow_from_dataframe(female_df, directory='./boneage-training-dataset', x_col='id', y_col='boneage',\n","                                              target_size=(224,224), color_mode='grayscale', \n","                                              class_mode='raw', subset='validation', shuffle=False)\n","\n","\n","printf(\"\\n******************** MAKE Gegerator ****************************\\n\")\n"]},{"cell_type":"code","source":["\n","# Identity Block\n","# class IdentityBlock(tf.keras.Model):\n","#     def __init__(self, filters, kernel_size):\n","#         super(IdentityBlock, self).__init__(name='')\n"," \n","#         self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n","#         self.bn1 = tf.keras.layers.BatchNormalization()\n"," \n","#         self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding='same')\n","#         self.bn2 = tf.keras.layers.BatchNormalization()\n"," \n","#         self.relu = tf.keras.layers.Activation('relu')\n","#         self.add = tf.keras.layers.Add()\n","    \n","#     def call(self, inputs):\n","#         x = self.conv1(inputs)\n","#         x = self.bn1(x)\n","#         x = self.relu(x)\n"," \n","#         x = self.conv2(x)\n","#         x = self.bn2(x)\n"," \n","#         x = self.add([x, inputs])\n","#         x = self.relu(x)\n"," \n","#         return x\n","\n","# class ResNet(tf.keras.Model):\n","#     def __init__(self, num_classes):\n","#         super(ResNet, self).__init__()\n","#         self.conv = tf.keras.layers.Conv2D(64, 7, padding='same')\n","#         self.bn = tf.keras.layers.BatchNormalization()\n","#         self.relu = tf.keras.layers.Activation('relu')\n","#         self.max_pool = tf.keras.layers.MaxPool2D((3, 3))\n","#         self.id1a = IdentityBlock(64, 3)\n","#         self.id1b = IdentityBlock(64, 3)\n","#         self.global_pool = tf.keras.layers.GlobalAveragePooling2D()\n","#         self.classifier = tf.keras.layers.Dense(num_classes, activation='softmax')\n","    \n","#     def call(self, inputs):\n","#         x = self.conv(inputs)\n","#         x = self.bn(x)\n","#         x = self.relu(x)\n","#         x = self.max_pool(x)\n"," \n","#         x = self.id1a(x)\n","#         x = self.id1b(x)\n"," \n","#         x = self.global_pool(x)\n","#         return self.classifier(x)\n","\n","# resnet = resnet(10)\n","# resnet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n","\n","# resnet.fit(train_generator, steps_per_epoch=100, epochs=1, validation_data=valid_generator, validation_steps=800)\n","# resnet.save(\"/content/drive/Shareddrives/growthPrediction/machineLearning/check_point_4\")\n"," \n"," \n"],"metadata":{"id":"yXsxkdFmiu7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NZhRXChZ5Vkm"},"outputs":[],"source":["checkpoint_m = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath=\"./check_point_m\")\n","checkpoint_f = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath=\"./check_point_f\")\n","\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","\n","history_m = male_model.fit_generator(train_generator_m, validation_data=valid_generator_m, epochs=1, callbacks=[checkpoint_m, early_stopping])\n","history_f = female_model.fit_generator(train_generator_f, validation_data=valid_generator_f, epochs=1, callbacks=[checkpoint_f, early_stopping])\n","\n","# male_model.fit(train_generator_m, steps_per_epoch=100, epochs=1, validation_data=valid_generator_m, validation_steps=800)\n","# female_model.fit(train_generator_f, steps_per_epoch=100, epochs=1, validation_data=valid_generator_f, validation_steps=800)\n","\n","# male_model.save(./check_point_m)\n","# female_model.save(./check_point_f)\n","printf(\"\\n******************** FINISH save model ****************************\\n\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"train_for_server.ipynb","provenance":[{"file_id":"1Qh9I2MC55ElJF5f6Bqs2r3cjIHSPzlZ6","timestamp":1654156404150},{"file_id":"1UUzIZf0NHC-cnjZiEoCPrioY9BkzzIZr","timestamp":1649930689917}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}